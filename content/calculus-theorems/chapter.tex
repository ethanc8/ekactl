\chapter{Calculus Theorems}

\newtheoremstyle{ethantheorem}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {}%                                     % Body font
  {}%                                     % Indent amount
  {\bfseries}%                            % Theorem head font
  {.}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {\thmname{#1}\thmnumber{ #2}\thmnote{ (#3)}}%    

\newtheoremstyle{ethannamedtheorem}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {}%                                     % Body font
  {}%                                     % Indent amount
  {\bfseries}%                            % Theorem head font
  {.}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {\thmnumber{#2 }\thmnote{#3}}%   

\newtheoremstyle{ethandefinition}%                % Name
  {}%                                     % Space above
  {}%                                     % Space below
  {}%                                     % Body font
  {}%                                     % Indent amount
  {}%                            % Theorem head font
  {.}%                                    % Punctuation after theorem head
  { }%                                    % Space after theorem head, ' ', or \newline
  {\thmname{\textit{#1}}\thmnumber{ #2}\thmnote{\textit{ of }\textbf{#3}}}%    

\theoremstyle{ethantheorem}
\newtheorem*{theorem}{Theorem}
\newtheorem*{procedure}{Procedure}

\theoremstyle{ethannamedtheorem}
\newtheorem*{namedtheorem}{Theorem}
\newtheorem*{namedprocedure}{Procedure}

\theoremstyle{ethandefinition}
\newtheorem*{definition}{Definition}

\section*{1 Completeness}
% \subsection*{1.3 Completeness}

\begin{theorem}[Completeness of the Real Numbers]
  Every nonempty subset $S$ of $\Real$ which is bounded above has a least upper bound $\sup S$.
\end{theorem}

\begin{definition}[Supremum ($\sup S$)]
  A number such that 
  \begin{enumerate}[(1)]
    \item $s \leq \sup S$ for every $s \in S$ (which just says that $\sup S$ is an upper bound for $S$)
    \item If $u$ is any upper bound for S, then $\sup S \leq u$ (which says that $\sup S$ is the least upper bound for $S$).
  \end{enumerate}
\end{definition}

\begin{definition}[Infimum ($\inf S$)]
  A number such that 
  \begin{enumerate}[(1)]
    \item $\inf S \leq s$ for every $s \in S$ (i.e. $\inf S$ is an lower bound for $S$)
    \item If $l$ is any upper bound for $S$, then $l \leq \inf S$ (i.e. $\inf S$ is the greatest lower bound for $S$).
  \end{enumerate}
\end{definition}

\begin{theorem}
  Every nonempty subset $S$ of $\Real$ which is bounded below has a greatest lower bound.
\end{theorem}

\begin{theorem}
  If $\min S$ exists, then $\min S = \inf S$.
\end{theorem}

\begin{theorem}
  If $A \subset R$ and $c \geq 0$, and $cA := {ca : a \in A}$, $\sup cA = c \sup A$.
\end{theorem}

% \subsection*{1.4 Consequences of Completeness}

\begin{theorem}[Rationals between Reals]
  For every two real numbers $a$ and $b$ with $a < b$, there exists a rational number $r$ satisfying $a < r < b$.
\end{theorem}

% \subsection*{1.5 Nested Intervals Theorem}

\begin{namedtheorem}[Nested Intervals Theorem] \leavevmode \\
  If $I_n = [a_n, b_n] = \{x \in R : a_n \leq x \leq b_n\}$ s.t. $a_n \leq a_{n + 1}$ and $b_{n+1} \leq b_n$ for $n \in \Natural$, so that $I_1 \supseteq I_2 \supseteq I_3 \supseteq I_4 \supseteq \ldots$, then $\displaystyle \bigcap_{n=1}^{\infty}I_n \neq \emptyset$.

  If $\inf \{b_n - a_n\} = 0$, then $\displaystyle \bigcap_{n=1}^{\infty}I_n = \{x\}$, where $x = \sup \{a_n\} = inf \{ b_n \}$.
\end{namedtheorem}

% \subsection*{1.6 Capture Theorem}

\begin{namedtheorem}[Capture Theorem] If $A$ is a nonempty subset of $\Real$, then:
  \begin{enumerate}[(i)]
    \item If $A$ is bounded above, then any open interval containing $\sup A$ contains an element of $A$.
    \item Similarly, if $A$ is bounded below, then any open interval containing $\inf A$ contains an element of $A$.
  \end{enumerate}
\end{namedtheorem}

% \subsection*{1.7 Binary Search}

\begin{theorem}[Binary Search (Bisection Method)]
If we binary-search for $x$ over $I_1 = [a_1, b_1]$ for $a_1, b_1 \in \Rational$, 
we define $I_n$ s.t. either $I_n := [a_{n-1}, \frac{a_{n-1} + b_{n-1}}{2}]$ or 
$I_n := [\frac{a_{n-1} + b_{n-1}}{2}, a_{n-1}]$, and we define $a_n := \inf I_n$ 
and $b_n := \sup I_n$. We define $A$ to be the set of all $a_n$, and $B$ to be 
the set of all $b_n$.

Then, the size of $I_n = \frac{b_1 - a_1}{2^n} = b_n - a_n$, and $\displaystyle \bigcap_{n=1}^{\infty}I_n \{x\}$, where $x = \sup \{a_n\} = \inf \{ b_n \}$.
\end{theorem}

\section*{2 Limits}

% \subsection*{2.4 $\varepsilon$-$\delta$ definition of a Limit}

\begin{definition}[Limit]
  If $\displaystyle\lim_{x \to a} f(x) = L$, then for any $\varepsilon > 0$, there exists $\delta > 0$ s.t. for any $x \in (a - \delta, a) \cup (a, a + \delta)$, $f(x) \in (L - \varepsilon, L + \varepsilon)$.
\end{definition}

Alternatively,

\begin{definition}[Limit]
  If $\displaystyle\lim_{x \to a} f(x) = L$, then for any $\varepsilon > 0$, there exists $\delta > 0$ s.t. $|f(x) - L| < \varepsilon$ whenever $0 < |x - a| < \delta$.
\end{definition}

\begin{definition}[Right-sided limit]
  If $\displaystyle\lim_{x \to a^+} f(x) = L$, then for any $\varepsilon > 0$, there exists $\delta > 0$ s.t. $|f(x) - L| < \varepsilon$ whenever $0 < x - a < \delta$.
\end{definition}

\begin{definition}[Left-sided limit]
  If $\displaystyle\lim_{x \to a^-} f(x) = L$, then for any $\varepsilon > 0$, there exists $\delta > 0$ s.t. $|f(x) - L| < \varepsilon$ whenever $0 < a - x < \delta$.
\end{definition}

% \subsection*{2.6 Limit Laws}

\begin{theorem}[Limit Laws]
  Let $c \in R$ be a constant and suppose the limits $\lim_{x \to a} f (x)$ and $\lim_{x \to a} g (x)$ exist. Then
  \begin{itemize}
  \item $\displaystyle\lim_{x \to a}( f (x) \pm g(x)) = \lim_{x \to a} f (x) \pm \lim_{x \to a} g(x)$
  \item $\displaystyle\lim_{x \to a}(c f (x)) = c \lim_{x \to a} f (x)$
  \item $\displaystyle\lim_{x \to a}( f (x)g(x)) = \lim_{x \to a} f (x) \lim_{x \to a} g(x)$
  \item $\displaystyle\lim_{x \to a} f (x) g(x) = \lim_{x \to a} f (x) \lim_{x \to a} g(x)$ , provided that $\displaystyle\lim_{x \to a} g(x) \neq 0$
  \item $\displaystyle\lim_{x \to a} x^n = (\lim_{x \to a} x)^n$
  % \item $\displaystyle\lim_{x \to a} \sqrt{f(x)} = \sqrt{\lim_{x \to a} f(x)}$ % by Composite Function Theorem
  \item $\displaystyle\lim_{x \to a} \frac{a(x)b(x)}{c(x)b(x)} = \lim_{x \to a} \frac{a(x)}{c(x)}$
  \end{itemize}
  These laws also apply to one-sided limits.
\end{theorem}

\begin{theorem}[L'Hopital's Rule]
  If $f$ and $g$ are differentiable and $g'(x) \neq 0$ on an open interval $I$ that surrounds $a$, and $\displaystyle\lim_{x \to a}\frac{f(x)}{g(x)} \in \{\frac{0}{0}, \pm\frac{\infty}{\infty}\}$, then $\displaystyle\lim_{x \to a}\frac{f(x)}{g(x)} = \lim_{x \to a}\frac{f'(x)}{g'(x)}$.
\end{theorem}

\begin{theorem}[Composition of Limits]
  If $f$ is continuous at $L$ and $\displaystyle\lim_{x \to a}g(x) = L$, then $\displaystyle\lim_{x \to a} f(g(x) = f(\lim_{x \to a} g(x))) = f(L)$
\end{theorem}

\begin{theorem}[Operations on infinity]
  For $x \in \Real$,
  \[
    \infty + x = \infty \qquad
    -\infty + x = -\infty \qquad
    \frac{x}{\pm\infty} = 0 
  \]\[
    x * \infty = \begin{cases}
      \infty & \text{if } x > 0 \\
      -\infty & \text{if } x < 0
    \end{cases}
  \]\[
    x * -\infty = \begin{cases}
      -\infty & \text{if } x > 0 \\
      \infty & \text{if } x < 0.
    \end{cases}
  \]
\end{theorem}

\begin{definition}[Indeterminate forms]
  The following forms are indeterminate and you cannot evaluate them.
  \[
    \frac{0}{0}, \frac{\pm\infty}{\pm\infty}, 0*\pm\infty, \infty - \infty
  \]
\end{definition}

% \subsection*{2.12 Squeeze Theorem}

\begin{namedtheorem}[Squeeze Theorem]
  Let $f$ , $g$, and $h$ be defined for all $x \neq a$ over an open interval containing $a$. If
  $$
    f(x) \leq g(x) \leq h(x)
  $$
  for all $x \neq a$ in an open interval containing $a$ and
  $$
  \lim_{x \to a} f (x) = L = \lim_{x \to a} h(x)
  $$
  where $L \in \Real$, then $\lim_{x \to a} g(x) = L$.
\end{namedtheorem}

\section*{3 Continuity}

\begin{definition}[Continuity at a point]
  Function $f$ is continuous at point $a$ if $\displaystyle\lim_{x \to a} f (x) = f (a)$.
\end{definition}

\begin{definition}
  $f$ has a \textbf{removable discontinuity} if $\displaystyle\lim_{x \to a} f (x) = L \in \Real$ (in this case either $f (a)$ is undefined, or $f (a)$ is defined by $L \neq f (a)$).
\end{definition}
\begin{definition}
  $f$ has a \textbf{jump discontinuity} if $\displaystyle\lim_{x \to a^-} f (x) = L_1 \in \Real$ and $\displaystyle\lim_{x \to a^+} f (x) = L_2 \in \Real$ but $L1 \neq L2$.
\end{definition}
\begin{definition}
  $f$ has an \textbf{infinite discontinuity} at $a$ if $\displaystyle\lim_{x \to a^-} f (x) = \pm\infty$ or $\displaystyle\lim_{x \to a^+} f (x) = \pm\infty$
\end{definition}

\begin{namedtheorem}[Intermediate Value Theorem]
  If $f$ is continuous on $[a, b]$, then for any real number $L$ between $f (a)$ and $f (b)$ there exists at least one $c \in [a, b]$ such that $f (c) = L$. In other
  words, if $f$ is continuous on $[a, b]$, then the graph must cross the horizontal line $y = L$ at least once
  between the vertical lines $x = a$ and $x = b$.
\end{namedtheorem}

\begin{namedtheorem}[Aura Theorem]
  If $f(x)$ is continuous and $f(a)$ is positive, then there exists an open interval containing $a$ such that for all $x$ in the interval, $f(x)$ is positive.

  If $f(x)$ is continuous and $f(a)$ is negative, then there exists an open interval containing $a$ such that for all $x$ in the interval, $f(x)$ is negative.
\end{namedtheorem}

\begin{namedtheorem}[Bolzano's Theorem]
  Let $f$ be a continuous function defined on $[a, b]$. If $0$ is between $f (a)$ and $f (b)$, then there exists $x \in [a, b]$ such that $f (x) = 0$.
\end{namedtheorem}

\pagebreak

\section*{4 Derivatives}

The derivative is the instantaneous rate of change, and the slope of the tangent line to the point.

\begin{definition}[Derivative ($f'(a)$)]
  \[
    \frac{d}{da} f(a) = f'(a) = \lim_{x \to a} \frac{f(x)-f(a)}{x - a} = \lim_{h \to 0} \frac{f(a+h)-f(a)}{h}
  \]
\end{definition}

\begin{theorem}[Tangent line to a point]
  The equation of the tangent line to the point $(a, f(a))$ is
  \[
    y = f'(a)(x-a) + f(a)
  \]
\end{theorem}

\subsection*{Derivative Rules}

\begin{theorem}[Difference Rule]
  \[
    \frac{d}{dx}(f(x) - g(x)) = \frac{d}{dx}f(x) - \frac{d}{dx}g(x)
  \]
\end{theorem}

\begin{theorem}[Sum Rule]
  \[
    \frac{d}{dx}(f(x) + g(x)) = \frac{d}{dx}f(x) + \frac{d}{dx}g(x)
  \]
\end{theorem}

\begin{theorem}[Constant Multiple Rule]
  \[
    \frac{d}{dx}(cf(x)) = c\frac{d}{dx}f(x)
  \]
\end{theorem}

\begin{theorem}[Product Rule]
  \[\begin{aligned}
    \frac{d}{dx}(f(x)g(x)) &= &f'(x)g(x) + f(x)g'(x) \\
    \frac{d}{dx}(f(x)g(x)h(x)) &= &f'(x)g(x)h(x) + f(x)g'(x)h(x) \\
                               &+ &f(x)g(x)h'(x)
  \end{aligned}\]
  and so on.
\end{theorem}

\begin{theorem}[Quotient Rule]
  \[
    \frac{d}{dx}\frac{f(x)}{g(x)} = \frac{f'(x)g(x) - f(x)g'(x)}{(g(x))^2}
  \]
\end{theorem}

\begin{theorem}[Power Rule]
  \[
    \frac{d}{dx} x^n = nx^{n-1}
  \]
  for $n \in \Real$
\end{theorem}

\begin{theorem}[Chain Rule]
  \[
    \frac{d}{dx}f(g(x)) = f'(g(x))g'(x) \qquad \frac{dy}{dx} = \frac{dy}{db}\frac{db}{dx}
  \]
\end{theorem}

\begin{theorem}[Derivative of inverse functions]
  Let $x \in \Real$ and $f$ be a differentiable, one-to-one function at $x$. Then if $f'(x) \neq 0$, then
  \[
    (f^{-1})'(f(x)) = \frac{1}{f'(x)}
  \]
\end{theorem}

\begin{theorem}[Derivatives of exponentials and logs]
  \[\begin{aligned}
    \frac{d}{dx} e^x &= e^x &
    \frac{d}{dx} \ln x &= \frac{1}{x} \\
    \frac{d}{dx} a^x &= a^x \ln(a)&
    \frac{d}{dx} \log_a x &= \frac{1}{x\ln(a)}
  \end{aligned}\]
\end{theorem}

\begin{theorem}[Derivatives of trig functions]\leavevmode\newline
  \textbf{Warning:} $x$ must be an angle in radians!
  \[\begin{aligned}
    \sin'(x) &= \cos(x) &
    \cos'(x) &= -\sin(x) \\
    \sec'(x) &= \sec(x)\tan(x) &
    \csc'(x) &= -\csc(x)\cot(x) \\
    \tan'(x) &= \sec(x)^2 &
    \cot'(x) &= -\csc(x)^2
  \end{aligned}\]
  \[\begin{aligned}
    \arcsin'(x) &= \frac{1}{\sqrt{1-x^2}} &
    \arccos'(x) &= -\frac{1}{\sqrt{1-x^2}} \\
    \arcsec'(x) &= \frac{1}{|x|\sqrt{x^2-1}} &
    \arccsc'(x) &= -\frac{1}{|x|\sqrt{x^2-1}} \\
    \arctan'(x) &= \frac{1}{1+x^2} &
    \arccot'(x) &= -\frac{1}{1+x^2}
  \end{aligned}\]
\end{theorem}

\section*{5 Derivative Applications}

\subsection*{5.7 Mean Value Theorem}

\begin{theorem}[Mean Value Theorem]
  If the function $f$ is continuous on $[a, b]$ and differentiable on $(a, b)$, then there exists $c \in (a, b)$ s.t.
  \[
    f'(c) = \frac{f(b) - f(a)}{b - a} = \frac{\Delta f(x)}{\Delta x} \text{ on } [a, be]
  \]
\end{theorem}

\begin{theorem}[Some colloraries to the MVT]
  If $f(x)$ is differentiable on $I$, then:
  \begin{itemize}
    \item $f'(x) > 0$ for $x \in I$ $\iff$ $f(x)$ is strictly increasing for $x \in I$.
    \item $f'(x) \geq 0$ for $x \in I$ $\iff$ $f(x)$ is increasing or constant for $x \in I$.
    \item $f'(x) = 0$ for $x \in I$ $\iff$ $f(x)$ is constant for $x \in I$.
    \item $f'(x) \leq 0$ for $x \in I$ $\iff$ $f(x)$ is decreasing or constant for $x \in I$.
    \item $f'(x) < 0$ for $x \in I$ $\iff$ $f(x)$ is strictly decreasing for $x \in I$.
  \end{itemize}
\end{theorem}

\subsection*{5.3, 5.10, 5.11, 5.16 Extrema}

\begin{definition}[Critical point of $f$]
  A number $c$ in the domain of $f$ where $f'(c) = 0$ or $f'(c)$ does not exist.
\end{definition}

\begin{definition}[Stationary point of $f$]
  A number $c$ in the domain of $f$ where $f'(c) = 0$
\end{definition}

\begin{namedtheorem}[Fermat's Theorem]
  The local maxima and minima of $f$ are critical points of $f$.
\end{namedtheorem}

\begin{namedtheorem}[Exteme Value Theorem]
  If $f$ is continuous on $[a, b]$, then it has an absolute max and an absolute min.
\end{namedtheorem}

\begin{theorem}[Method to find absolute minima and maxima]
  Store the critical points of $f$ in the array $C$. Then, the absolute maximum is $\max \{f(c) : c \in C\}$ and the absolute minimum is $\min \{f(c) : c \in C\}$.
\end{theorem}

\begin{theorem}[First Derivative Test]
  If $f$ is continuous over $I$, and $c \in I$ is a critical point of $f$, and $f$ is differentiable over $I \setminus {c}$, then:

  \begin{itemize}
    \item If $f'(x)$ is decreasing at $c$, then $f(c)$ is a local max.
    \item If $f'(x)$ is increasing at $c$, then $f(c)$ is a local min.
    \item If $f'(x)$ has the same sign before and after $c$, then $f(c)$ is neither a local max nor a local min.
  \end{itemize}
\end{theorem}

\begin{definition}[Concavity]
  $f$ is concave up on $I$ if the tangent line to $f$ at each point in $I$ is lower than the graph of $f$.

  $f$ is concave down on $I$ if the tangent line to $f$ at each point in $I$ is higher than the graph of $f$.
\end{definition}

\begin{theorem}[Test for Concavity]
  If $f''(x) > 0$ for all $x \in I$, then $f$ is concave up on $I$.

  If $f''(x) < 0$ for all $x \in I$, then $f$ is concave down on $I$.
\end{theorem}

\begin{theorem}[Second Derivative Test]
  If $f''$ is continuous on an interval containing $c$, where $c$ is the $x$-value of a stationary point of $f$. Then,
  \begin{itemize}
    \item If $f''(c) > 0$, then $f(c)$ is a local max.
    \item If $f''(c) < 0$, then $f(c)$ is a local min.
  \end{itemize}
\end{theorem}

\begin{namedtheorem}[Trimm's Single Extremum Theorem]
  If $f$ is continuous on an interval $I$, and $f$ has a single local extremum (max or min), then that extremum is a global max or min.
\end{namedtheorem}

\columnbreak

\section*{5 Integrals}

\subsection*{Antiderivative}

\begin{definition}[Antiderivative / Indefinite Integral]
  The antiderivative $F$ of a function $f$ is the function such that $F'(x) = f(x)$.
  \[
    F(x) = \int f(x) dx
  \]
\end{definition}

\begin{theorem}[Antiderivative plus a constant]
  If $F$ is the antiderivative of a function $f$, then $G(x) = F(x) + c$ where $c \in \Real$ is also an antiderivative.
\end{theorem}

\begin{definition}[Integral]
  \[
    (f_1 [a, b]) \mapsto \int_a^b f(x)dx \in \Real
  \]
  such that the Properties of the Integral are true.
\end{definition}

The definite integral takes in a function and a range $[a, b]$, and returns a number. The indefinite integral takes in a function and returns an infinitely large set of functions (the antiderivatives).

If $a > b$, then $\int_a^b f := -\int_b^a f$.

Let $\mathcal{R}([a,b])$ be the set of integrable functions, $\mathcal{C}([a,b])$ be the set of continuous functions, and $\mathcal{B}([a,b])$ be the set of bounded functions on $[a, b]$. Then
\[
  \mathcal{C}([a,b]) \subset \mathcal{R}([a,b]) \subset \mathcal{B}([a,b])
\]

\begin{theorem}[Properties of the Integral]
  The integral is defined such that the following are true:
  \begin{enumerate}[start=0,label={(I\arabic*)}]
    \item Every continuous function is integrable.
    \item If $f(x) = c$, then $\int_a^b f(x) dx = c(b - a)$
    \item If $f_1(x) \leq f_2(x)$, then $\int_a^b f_1(x)dx \leq \int_a^b f_2(x)dx$.
    \item For any $a$, $b$, $c$, $\displaystyle \int_a^b f(x)dx = \int_a^c f(x)dx + \int_c^b f(x)dx$.
  \end{enumerate}
\end{theorem}

\begin{theorem}[Fundamental Theorem of Calculus]
  Let $f \in \mathcal{R}([a, b])$ be some integrable function, where $a, b \in \Real$. Let $\mathcal{F}(x) = \int_a^x f$ for $x \in [a, b]$. Then:
  \begin{enumerate}[(a)]
    \item $\mathcal{F}$ is continuous for every $c \in [a, b]$.
    \item If $f$ is continuous at $c \in [a. b]$, then $\mathcal{F}$ is diffentiable at $c$, and $\mathcal{F}'(c) = f(c)$.
    \item If $f$ is continuous on $[a, b]$, and $F$ is an antiderivative of $f$, then $\int_a^b f = F(b) - F(a)$, or
      \[
        \int_a^b f(x) dx = F(x) \bigg\rvert_a^b = F(b) - F(a)
      \]
  \end{enumerate}
\end{theorem}

\begin{theorem}[Substitution Rule]
  If $g$ is a function that has a continuous derivative on an interval, another function $f$ is continuous on the range of $g$, and $F$ is an antiderivative of $f$ on the range of $g$, then
  \[
    \int f(g(x)) g'(x) dx = F(g(x)) + C
  \]
  For $a, b \in \Real$,
  \[
    \int_a^b f(g(x))g'(x)dx = \int_{g(a)}^{g(b)} f(u) du = F(g(b)) - F(g(a))
  \]
  Let $u := g(x)$. Then, if $du = E (g'(x) dx)$, where $E \in \Real$, then 
  \[
    \int E f(u) du = E \int f(u) du = F(u) + C
  \]
\end{theorem}

\begin{theorem}[Some Antiderivative Rules]
  \[\begin{aligned}
    \int e^x dx &= e^x + C & \int x^a dx &= \frac{x^{a + 1}}{a + 1} + C \text{ for } a \neq 1 \\
    \int a^x dx &= \frac{a^x}{\ln(a)} + C & \int x^{-1} dx &= \ln |x| + C \\
  \end{aligned}\]\[\begin{aligned}
    \int f(x) + g(x) dx &= \int f(x) dx + \int g(x) dx \\
  \end{aligned}\]
\end{theorem}

\begin{theorem}[Integration By Parts]
  If $f$ and $g$ are integrable functions, then
  \[
    \int f(x) g'(x) dx = f(x) g(x) + \int f(x) g(x) dx
  \]
  Equivalently, if $u$ and $v$ are integrable functions of $x$, then
  \[
    \int udv = uv - \int vdu
  \]
  Additionally, if $f'$ and $g'$ are continuous, then
  \[
    \int_a^b f(x) g'(x) dx = f(b)g(b) - f(a)g(a) + \int_a^b g(x) f'(x) dx
  \]
\end{theorem}

\begin{theorem}[Integrals of Trig Functions]
  \[\begin{aligned}
    \int \sin(x) dx &= -\cos(x) + C & \int \cos(x) dx &= \sin(x) + C \\
  \end{aligned}\]
  \[\begin{aligned}
    \int \tan(x) dx &= -\ln |\cos(x)| + C = \ln |\sec(x)| + C \\
    \int \cot(x) dx &= \ln |\sin(x)| + C = -\ln |\csc(x)| + C \\
    \int \sec(x) dx &= \ln |\sec(x) + \tan(x)| + C \\
    \int \csc(x) dx &= -\ln |\cot(x) + \csc(x)| + C
  \end{aligned}\]
\end{theorem}


% If m is odd, then $m=2k+1$ for some integer k. Rewrite
%   \[
%     \sin^m (x) = \sin^{2k+1}x = \sin^{2k}x \sin x = (\sin^2 x)^k \sinx=(1-\cos^2 x)k \sin x
%   \]
%   Then
%   \[
%     \int \sin^m (x) \cos^m (x) dx = \int (1-\cos^2 x)k \sin (x) \cos^m (x) = - \int (1 - u^2)^k u^n du
%   \]
  
%   where $u=\cos x$ and $du=-\sin x dx$.

% \begin{procedure}[Integral of Powers of Sine and Cosine]
%   Consider $\int \sin^m (x) \cos^n (x) dx$, where m,n are nonnegative integers.
  
%   If m is odd, then $m=2k+1$ for some integer k. Then
%   \[
%     \int \sin^m (x) \cos^m (x) dx = - \int (1 - u^2)^k u^n du
%   \]
  
%   where $u=\cos x$ and $du=-\sin x dx$.
  
%   If n is odd, then $m=2k+1$ for some integer k. Then
%   \[
%     \int \sin^m (x) \cos^m (x) dx = \int u^m (1 - u^2)^k du
%   \]
  
%   where $u=\sin x$ and $du=\cos x dx$.

%   If both m and n are even, use the power--reducing identities
%   \[
%     \cos^2x = \frac{1+\cos (2x)}{2} \quad \text{and}\quad \sin^2x = \frac{1-\cos(2x)}2
%   \]
%   to reduce the degree of the integrand. Expand the result and apply this procedure again.
% \end{procedure}

% \begin{theorem}[Multiplications of Sinusoidal Functions]
%   \[\begin{aligned}
%     \int \sin(mx) \cos(nx) dx &= -\frac{\cos((n + m) x)}{2 (n + m)} - \frac{\cos((m - n) x)}{2 (m - n)} \\
%     \int \sin(mx) \sin(nx) dx &= \frac{\sin((m - n) x)}{2 (m - n)} - \frac{\sin((n + m) x)}{2 (n + m)} \\
%     \int \cos(mx) \cos(nx) dx &= \frac{\sin((n + m) x)}{2 (n + m)} + \frac{\sin((m - n) x)}{2 (m - n)}
%   \end{aligned}\]
% \end{theorem}

% \begin{theorem}[Tangent/Secant Reduction Formulas]
%   \begin{align*}
%     \int\sec^n x\,dx &= \frac{1}{n-1}\sec^{n-2}x \tan x+\frac{n-2}{n-1}\int\sec^{n-2}x\,dx \\
%     \int\csc^n x\,dx &= -\frac{1}{n-1}\csc^{n-2}x \cot x+\frac{n-2}{n-1}\int\csc^{n-2}x\,dx \\
%     \int\tan^n x\,dx &= \frac{1}{n-1}\tan^{n-1}x-\int\tan^{n-2}x\,dx \\
%     \int\cot^n x\,dx &= -\frac{1}{n-1}\cot^{n-1}x-\int\cot^{n-2}x\,dx \\
%   \end{align*}
% \end{theorem}

\begin{procedure}[Integrals of Powers of Trig Functions] \ \\
  To solve $\int \sin^n(x) \,dx$ where $n$ is even, substitute $\sin^2 (x) = \tfrac{1}{2} (1 - \cos(2x))$.

  To solve $\int \sin^n(x) \,dx$ where $n$ is odd, substitute $\sin^2 (x) = 1 - \cos^2 (x)$ and perform u-sub with $u := \cos^2 (x)$ and $du = -\sin(x) \,dx$.

  To solve $\int \cos^n(x) \,dx$ where $n$ is even, substitute $\cos^2 (x) = \tfrac{1}{2} (1 + \cos(2x))$.

  To solve $\int \cos^n(x) \,dx$ where $n$ is odd, substitute $\cos^2 (x) = 1 - \sin^2 (x)$ and perform u-sub with $u := \sin^2 (x)$ and $du = \cos(x) \,dx$.

  To solve $\int \tan^n(x) \,dx$, substitute $\tan^2 (x) = \sec^2 (x) - 1$. If $n$ is odd, perform u-sub with $u := \sec(x)$ and $du = \sec(x)\tan(x)\,dx$.

  To solve $\int \cot^n(x) \,dx$, substitute $\cot^2 (x) = \csc^2 (x) - 1$. If $n$ is odd, perform u-sub with $u := \csc(x)$ and $du = -\csc(x)\cot(x)\,dx$.

  To solve $\int \sec^n(x) \,dx$ where $n$ is even, substitute $\sec^2(x) = \tan^2(x) + 1$, but ensure that $\sec^2(x)\,dx$ remains. Then perform u-sub with $u := \tan(x)$ and $du = \sec^2(x)\,dx$.

  To solve $\int \sec^n(x) \,dx$ where $n$ is odd, substitute $\sec^n(x) = \frac{1}{\cos^n(x)} \frac{\cos(x)}{\cos(x)}$. Then substitute $\cos^2(x) = (1 + u)(1 - u)$ and u-sub with $u := \sin(x)$ and $du = \cos(x) dx$. Then perform partial fraction decomposition.

  To solve $\int \csc^n(x) \,dx$ where $n$ is even, substitute $\csc^2(x) = \csc^2(x) + 1$, but ensure that $\sec^2(x)\,dx$ remains. Then perform u-sub with $u := \cot(x)$ and $du = -\csc^2(x)\,dx$.

  To solve $\int \csc^n(x) \,dx$ where $n$ is odd, substitute $\csc^n(x) = \frac{1}{\sin^n(x)} \frac{\sin(x)}{\sin(x)}$. Then substitute $\sin^2(x) = (1 + u)(1 - u)$ and u-sub with $u := \cos(x)$ and $du = -\sin(x) dx$. Then perform partial fraction decomposition.

  Remember that $\int \sec^2(x) \,dx = \tan(x)$ and $\int \csc^2(x) \,dx = -\cot(x)$. 
\end{procedure}

\begin{procedure}[Trig Substitution]
  \begin{center}
    \begin{tabular}{L L L} 
      % \hline
      \text{Orig expression} & \text{Substitution} & \text{Pythagorean identity} \\ 
      \hline
      \sqrt{a^2 - x^2} & x := a \sin(\theta) & 1 - \sin^2(\theta) = \cos^2(\theta) \\
      \sqrt{a^2 + x^2} & x := a \tan(\theta) & 1 + \tan^2(\theta) = \sec^2(\theta) \\
      \sqrt{x^2 - a^2} & x := a \sec(\theta) & \sec^2(\theta) - 1 = \tan^2(\theta)
      % \hline
    \end{tabular}
  \end{center}
\end{procedure}

\subsection*{Partial Fraction Decomposition}

\begin{theorem}
  Any polynomial $Q(x)$ with real coefficients can be factored over the reals as a product of two types of factors:
  \begin{itemize}
    \item linear factors (of the form $ax+b$)
    \item irreducible quadratic factors (of the form $ax^2 + bxx + c$, where $b^2-4ac < 0$)
  \end{itemize}
\end{theorem}

\begin{definition}[Proper rational function]
  A rational function $\frac{P(x)}{Q(x)}$ where $\deg P < \deg Q$.
\end{definition}

\begin{theorem}
  Any rational function can be converted into a proper rational function plus a polynomial by continually long-dividing by the denominator.
\end{theorem}

\begin{theorem}
  Let $R(x) = \frac{P(x)}{Q(x)}$ be a proper rational function, where the denominator $Q(x)$ has been factored into linear and irreducible quadratic factors. $R(x)$ can be written as a sum of partial fractions, where each factor in the denominator gives rise to terms in the partial fraction decomposition:
  \begin{itemize}
    \item For each factor of the form $(ax+b)^k$ in the denominator, add $\displaystyle \sum_{i=1}^k \frac{A_i}{(ax+b)^i}$ to the partial fraction decomposition.
    \item For each factor of the form $(ax^2 + bx + c)^k$ in the denominator, add $\displaystyle \sum_{i=1}^k \frac{A_i x + B_i}{(ax^2 + bx + c)^i}$ to the partial fraction decomposition.
  \end{itemize}
\end{theorem}

\subsection*{Riemann Sums}

\begin{definition}[Elementary function]
  A function which is a polynomial, rational function, power function ($x^a$), exponential function ($a^x$), logarithmic functions, trigonometric and inverse trigonometric functions, or an addition, subtraction, multiplication, division, and composition of the above.
\end{definition} 

\begin{definition}[Riemann sum]
  Let $f : [a, b] arrow \Real$ be any bounded function and let $P$ be a partition of $[a, b]$.
  \begin{itemize}
    \item A choice of a point ${x_i^*} \in [x_{i-1}, x_{i}]$ for all $i \in [1, n]$ is called a \textit{tagging} of $P$, which we denote by $\tau = {x_1^*, ..., x_n^*}$.
    \item A pair $(P, \tau)$ is called a \textit{tagged partition}.
    \item Given a bounded function $f : [a, b] arrow \Real$ and a tagged partition $(P, \tau)$ of $[a, b]$, the sum 
    \[
      R(f, P, \tau) = \sum_{i=1}^{n} f(x_i^*)(x_i - x_{i-1})
    \]
    is called the \textit{Riemann sum} of $f$ for $(P, \tau)$.
  \end{itemize}
\end{definition}

\begin{theorem}
  If $f$ is integrable on $[a, b]$, then for every $\varepsilon > 0$ there exists $\delta > 0$ s.t. if $P$ is a partition of $[a, b]$ with $|P| := \max{x_i - x_{i-1}} < \delta$ and $\tau = \{x_i^*\}$, then 
  \[
    | R(f, P, \tau) - \int_a^b f(x) dx | < \varepsilon
  \] 
\end{theorem}

\subsection*{Approximate Integration}

\begin{definition}[Left-endpoint approximation]
  Take $x_i^* = x_{i-1} = a + \frac{(i-1)(b-a)}{n}$. Then the left-endpoint approximation of the function $f(x)$ is
  \[
    \int_a^b f(x) dx \approx \sum_{i=1}^n f(a + \frac{(i-1)(b-a)}{n}) \frac{b-a}{n}
  \]
  The error bound is
  \[
    E_n^L \leq \max\{|f'(x)|\}_{x \in [a, b]} \frac{(b-a)^2}{2n}
  \]
\end{definition}

\begin{definition}[Right-endpoint approximation]
  Take $x_i^* = x_{i-1} = a + \frac{(i)(b-a)}{n}$. Then the right-endpoint approximation of the function $f(x)$ is
  \[
    \int_a^b f(x) dx \approx \sum_{i=1}^n f(a + \frac{(i)(b-a)}{n}) \frac{b-a}{n}
  \]
  The error bound is
  \[
    E_n^R \leq \max\{|f'(x)|\}_{x \in [a, b]} \frac{(b-a)^2}{2n}
  \]
\end{definition}

\begin{definition}[Midpoint approximation]
  Take $x_i^* = x_{i-1} = a + \frac{(i-\frac{1}{2})(b-a)}{n}$. Then the midpoint approximation of the function $f(x)$ is
  \[
    \int_a^b f(x) dx \approx \sum_{i=1}^n f(a + \frac{(i-\frac{1}{2})(b-a)}{n}) \frac{b-a}{n}
  \]
  The error bound is
  \[
    E_n^M \leq \max\{|f''(x)|\}_{x \in [a, b]} \frac{(b-a)^3}{24n^2}
  \]
\end{definition}

\begin{definition}[Trapezoidal approximation]
  Then the trapezoidal approximation of the function $f(x)$ is
  \[
    \int_a^b f(x) dx \approx \frac{b-a}{2n} (f(a) + 2 \sum_{i=1}^{n-1} f(a + \frac{(i)(b-a)}{n}) + f(b))
  \]
  The error bound is
  \[
    E_n^T \leq \max\{|f''(x)|\}_{x \in [a, b]} \frac{(b-a)^3}{12n^2}
  \]
\end{definition}

\begin{definition}[Simpson's approximation]
  For even $n$ (greater values of $n$ give more precise more accuracy):
  \[
    % \int_a^b f(x) dx \approx 
    \frac{b-a}{3n} \left(f(a) + \sum_{i=1}^{n-1} (3 - (-1)^i) f\left(a + \frac{(i)(b-a)}{n}\right) + f(b)\right)
  \]
  The error bound is
  \[
    E_n^S \leq \max\{|f''''(x)|\}_{x \in [a, b]} \frac{(b-a)^5}{180n^4}
  \]
\end{definition}

\section*{8 Integral Applications}

\subsection*{Volumes}

Generally, if $A(x)$ is the cross-section of a solid that intersects the $x$-axis at $x$, then the volume of the solid is
\[
  V = \int_a^b A(x) dx
\]

\begin{theorem}[Disk Method] Let $f(x)$ be a continuous, nonnegative function defined on $[a, b]$, and $R$ be the region bounded above by the graph of $f(x)$ and below by the $x$-axis. Then, the volume of the solid of revolution formed by revolving $R$ around the $x$-axis is given by
  \[
    V = \int_a^b \pi (f(x))^2 dx
  \]
\end{theorem}

\begin{theorem}[Washer Method] Let $f(x)$ be a continuous, nonnegative function defined on $[a, b]$, and $R$ be the region bounded above by the graph of $f(x)$ and below by the graph of $g(x)$. Then, the volume of the solid of revolution formed by revolving $R$ around the $x$-axis is given by
  \[
    V = \int_a^b \pi ((f(x))^2 - (g(x))^2) dx
  \]
\end{theorem}

\begin{theorem}[Cylindrical Shells Method] Let $f(x)$ be a continuous, nonnegative function defined on $[a, b]$, and $R$ be the region bounded above by the graph of $f(x)$ and below by the $x$-axis. Then, the volume of the solid of revolution formed by revolving $R$ around the $y$-axis is given by
  \[
    V = \int_a^b 2\pi x f(x) dx
  \]
\end{theorem}

\subsection*{Other things}

\begin{theorem}[Arc length of a curve]
  The arc length of the curve $f(x)$ on $[a, b]$, when $f'(x)$ exists and is continuous on $[a, b]$, is
  \[
    \int_a^b \sqrt{1 + \left(f'(x)\right)^2} dx
  \]
\end{theorem}

\begin{theorem}[Surface area of a solid of revolution]
  Let $f(x)$ be a continuous, nonnegative function defined on $[a, b]$, and $R$ be the region bounded above by the graph of $f(x)$ and below by the $x$-axis. Then, the surface area of the solid of revolution formed by revolving $R$ around the $x$-axis is given by
  \[
    S = \int_a^b 2\pi f(x) \sqrt{1 + \left(f'(x)\right)^2} dx
  \]
\end{theorem}

\begin{theorem}[Mass of a thin rod]
  Let there be a rod whose left end is located at $x = a$ and whose right end is located at $x = b$, and which is on the $x$-axis. Let $\rho(x)$ be the linear density at the point $x = a$. Then the mass of the rod is
  \[
    M = \int_a^b \rho(x) \,dx
  \]
\end{theorem}

\begin{theorem}[Mass of a thin disk]
  Let there be a disk of radius $R$ whose center is at the origin of the $xy$-plane. Let the mass be distributed in a rotationally-symmetric way. Let $\rho(r)$ be the radial density at the radius $r$. Then the mass of the disk is 
  \[
    M = \int_0^R 2\pi r \rho(r) dr
  \]
\end{theorem}

\begin{theorem}[Work]
  If an object moves along the $x$-axis from $a$ to $b$, and $F(x)$ is the force applied to the object when the object is at the point $x$ on the $x$-axis, then the work is
  \[
    \int_a^b F(x) \,dx
  \]
\end{theorem}

\begin{definition}[Average value of a function]
  If $f$ is continuous on $[a, b]$, then the average value of $f$ on $[a, b]$ is
  \[
    f_{\text{avg}} := \lim_{n \to \inf} \frac{1}{b - a} \int_a^b f(x) \,dx
  \]
\end{definition}

\begin{theorem}[Mean Value Theorem for Integrals]
  If $f$ is continuous on $[a, b]$, then there exists $c \in [a, b]$ such that
  \[
    f(c) = f_{\text{avg}} = \frac{1}{b-a} \int_a^b f(x) \,dx
  \]
  Equivalently,
  \[
    \int_a^b f(x) \,dx = f(c)(b - a)
  \]
  If $f$ is positive on $[a, b]$, then there is a number $c$ such that the rectangle with base $[a, b]$ and height $f(c)$ has the same area as $\int_a^b f(x) \,dx$.
\end{theorem}

\section{Improper Integrals}

\begin{definition}[Improper Integrals with Infinite Bounds] \ \\
  \begin{enumerate}
    \item[(a)] If $\int_a^t f(x)$ exists for every $t \geq a$, then we define
    \[
      \int_a^\infty f(x) dx := \lim_{t \to \infty} \int_a^t f(x) dx
    \]
    provided that this limit exists and is finite.

    \item[(b)] If $\int_t^b f(x) dx$ exists for every $t \leq b$, then we define
    \[
      \int_{-\infty}^b f(x)dx := \lim_{t \to -\infty} \int_t^b f(x)dx
    \]
    provided that this limit exists and is finite.
  \end{enumerate}

  $\int_a^\infty f(x)dx$ and $\int_{-\infty}^b f(x)dx$ are \textit{convergent} if the corresponding limit exists and \textit{divergent} if the limit doesn't exist.

  \begin{enumerate}
    \item[(c)] If both $\int_a^\infty f(x)dx$ and $\int_{-\infty}^b f(x)dx$ are convergent, then we define
    \begin{align*}
      \int_{-\infty}^{\infty} f(x)dx &= \int_{-\infty}^a f(x) dx + \int_a^\infty f(x) dx \\
                              &= \lim_{s \to -\infty} \int_s^a f(x) dx + \lim_{t \to \infty} \int_a^t f(x) dx
    \end{align*}
  \end{enumerate}
\end{definition}

\begin{definition}[Improper Integrals with Discontinuous Integrand] \ \\
  \begin{enumerate}
    \item[(a)] If $f$ is continuous on $[a, b)$ and is discontinuous at $b$, then define
    \[
      \int_a^b f(x) dx := \lim_{t \to b^-} \int_a^t f(x) dx
    \]
    provided that this limit exists and is finite.

    \item[(b)] If $f$ is continuous on $(a, b]$ and is discontinuous at $a$, then define
    \[
      \int_a^b f(x)dx := \lim_{t \to a^+} \int_t^b f(x)dx
    \]
    provided that this limit exists and is finite.
  \end{enumerate}

  $\int_a^\infty f(x)dx$ and $\int_{-\infty}^b f(x)dx$ are \textit{convergent} if the corresponding limit exists and \textit{divergent} if the limit doesn't exist.

  \begin{enumerate}
    \item[(c)] If $f$ has a discontinuity at $c$, where $a < c < b$, and both $\int_a^c f(x) dx$ and $\int_c^b f(x) dx$ are convergent, then we define
    \begin{align*}
      \int_a^b f(x)dx &= \int_a^c f(x) dx + \int_c^b f(x) dx \\
                                &= \lim_{s \to c^-} \int_a^s f(x) dx + \lim_{t \to c^+} \int_c^b f(x) dx
    \end{align*}
  \end{enumerate}
\end{definition}

\begin{theorem}[Comparison Test]
  Suppose $f$ and $g$ are continuous functions with $f(x) \geq g(x) \geq 0$ for $x \geq a$.
  \begin{itemize}
    \item[(a)] If $\int_a^\infty f(x)dx$ is convergent, then $\int_a^\infty g(x)dx$ is convergent.
    \item[(b)] If $\int_a^\infty g(x)dx$ is divergent, then $\int_a^\infty f(x)dx$ is divergent.
  \end{itemize}
  Additionally,
  \begin{itemize}
    \item[(a)] If $\int_{-\infty}^b f(x)dx$ is convergent, then $\int_{-\infty}^b g(x)dx$ is convergent.
    \item[(b)] If $\int_{-\infty}^b g(x)dx$ is divergent, then $\int_{-\infty}^b f(x)dx$ is divergent.
  \end{itemize}
\end{theorem}

\begin{theorem}[Limit Comparison Test]
  Suppose $f(x)$ and $g(x)$ are positive continuous functions defined on $[a, \infty)$ such that $\displaystyle \lim_{x \to \infty} \frac{f(x)}{g(x)} = c$ for some positive real number $c$. Then $\int_a^\infty f(x) dx$ converges iff $\int_a^\infty g(x) dx$.
\end{theorem}

\section{Differential Equations}

\begin{definition}[Differential equation] An equation involving an unknown function $y = f(x)$ and one or more of its derivatives.
\end{definition}

\begin{definition}[Solution to a differential equation] A function $y = f(x)$ that satisfies the differential equation when $f$ and its derivatives are substituted into the equation.
\end{definition}

% \begin{procedure}[Making a direction field] This procedure can be used to approximately graph a differential equation, even if an explicit solution cannot be found.
  
%   Factor the equation in terms of $y' = f'(x)$. At each $x,y$-value on a grid of a graph, evaluate $y'$ and draw a short line with the slope $y'$ at the $x,y$-value.
% \end{procedure}

\begin{procedure}[Euler's Method] This procedure numerically approximates a solution to a differential equation.
\end{procedure}
